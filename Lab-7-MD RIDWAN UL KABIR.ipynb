{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd00b6c-5d4a-4668-9963-ef0053f65894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 In SVM, the margin is the distance between the separating hyperplane (decision boundary) and the closest data points from each class, which are called support vectors. The equations for the two margin hyperplanes H+ and H- are typically w.x + b = 1 for H+ and w.x + b = -1 for H-, where w is the weight vector, x is the input vector, and b is the bias.\n",
      "\n",
      "Linear SVM that optimally separates the classes by maximizing the margin:\n",
      "-1.0 * x1 + 1.0 * x2 + 2.0 = 0\n",
      "\n",
      "1.3 A kernel function is a computational tool in SVMs that allows the algorithm to operate in a high-dimensional space without explicitly calculating the coordinates of the data in that space. It's a way to implicitly map input data into higher-dimensional space, making it possible to perform linear separation when the data is not linearly separable in the original input space. Common kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid.\n"
     ]
    }
   ],
   "source": [
    "# Question 1.1\n",
    "print(\"1.1 In SVM, the margin is the distance between the separating hyperplane (decision boundary) \"\n",
    "      \"and the closest data points from each class, which are called support vectors. The equations \"\n",
    "      \"for the two margin hyperplanes H+ and H- are typically w.x + b = 1 for H+ and w.x + b = -1 for H-, \"\n",
    "      \"where w is the weight vector, x is the input vector, and b is the bias.\\n\")\n",
    "\n",
    "\n",
    "# Define the points\n",
    "x1 = (2, 0)\n",
    "x2 = (0, 2)\n",
    "\n",
    "# Compute weights (w1, w2)\n",
    "w1 = (x2[1] - x1[1]) / (x2[0] - x1[0])\n",
    "w2 = -((x2[1] - x1[1]) / (x2[0] - x1[0]))\n",
    "\n",
    "# Compute the offset (b) for the point (2,0)\n",
    "b = -w1 * x1[0] - w2 * x1[1]\n",
    "\n",
    "# Print the linear SVM equation\n",
    "print(\"Linear SVM that optimally separates the classes by maximizing the margin:\")\n",
    "print(f\"{w1} * x1 + {w2} * x2 + {b} = 0\\n\")\n",
    "\n",
    "\n",
    "# Question 1.3\n",
    "print(\"1.3 A kernel function is a computational tool in SVMs that allows the algorithm to operate in a \"\n",
    "      \"high-dimensional space without explicitly calculating the coordinates of the data in that space. \"\n",
    "      \"It's a way to implicitly map input data into higher-dimensional space, making it possible to \"\n",
    "      \"perform linear separation when the data is not linearly separable in the original input space. \"\n",
    "      \"Common kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02d8e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "Accuracy with SVM linear kernel: 0.5573770491803278\n",
      "Accuracy with SVM rbf kernel: 0.5245901639344263\n",
      "Accuracy with SVM sigmoid kernel: 0.5245901639344263\n",
      "\n",
      "Neural Network Results:\n",
      "Accuracy with Neural Network sgd optimizer: 0.4262295081967213\n",
      "Accuracy with Neural Network adam optimizer: 0.4426229508196721\n",
      "\n",
      "Based on the model evaluation, the SVM with a linear kernel outperforms the other models, achieving an accuracy of approximately 55.74%. This higher performance suggests that the heart disease dataset might be linearly separable to some extent, making the linear kernel effective in finding a separating hyperplane.\n",
      "\n",
      "In contrast, the SVM models with RBF and Sigmoid kernels, as well as the Neural Network models with SGD and Adam optimizers, yield lower accuracies (ranging from 42.62% to 52.46%). These results indicate that for this particular dataset, the complexity introduced by non-linear kernels and the multi-layer architecture of the Neural Networks does not necessarily lead to better classification performance.\n",
      "\n",
      "The superior performance of the SVM with a linear kernel could be attributed to its simplicity and robustness, particularly in scenarios where the data exhibits a linear relationship or when the dataset size and feature space complexity do not justify more complex models.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "df = pd.read_csv('heart-disease-dataset1.csv')\n",
    "\n",
    "\n",
    "df = df.replace('?', np.nan)\n",
    "\n",
    "\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "\n",
    "X = df.drop('result', axis=1).values\n",
    "y = df['result'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "print(\"SVM Results:\")\n",
    "kernels = ['linear', 'rbf', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "    svm_clf = svm.SVC(kernel=kernel)\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    y_pred = svm_clf.predict(X_test)\n",
    "    print(f\"Accuracy with SVM {kernel} kernel: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nNeural Network Results:\")\n",
    "optimizers = ['sgd', 'adam']\n",
    "for optimizer in optimizers:\n",
    "    nn_clf = MLPClassifier(solver=optimizer, alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1,\n",
    "                           max_iter=1000, learning_rate_init=0.001, early_stopping=True)\n",
    "    nn_clf.fit(X_train, y_train)\n",
    "    y_pred = nn_clf.predict(X_test)\n",
    "    print(f\"Accuracy with Neural Network {optimizer} optimizer: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "print(\"\"\"\n",
    "Based on the model evaluation, the SVM with a linear kernel outperforms the other models, achieving an accuracy of approximately 55.74%. This higher performance suggests that the heart disease dataset might be linearly separable to some extent, making the linear kernel effective in finding a separating hyperplane.\n",
    "\n",
    "In contrast, the SVM models with RBF and Sigmoid kernels, as well as the Neural Network models with SGD and Adam optimizers, yield lower accuracies (ranging from 42.62% to 52.46%). These results indicate that for this particular dataset, the complexity introduced by non-linear kernels and the multi-layer architecture of the Neural Networks does not necessarily lead to better classification performance.\n",
    "\n",
    "The superior performance of the SVM with a linear kernel could be attributed to its simplicity and robustness, particularly in scenarios where the data exhibits a linear relationship or when the dataset size and feature space complexity do not justify more complex models.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922c03a-b9a4-4a38-aa2d-a8d7ead81993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81555216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
